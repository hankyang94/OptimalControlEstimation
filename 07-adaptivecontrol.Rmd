# Adaptive Control {#adaptivecontrol}

## Model-Reference Adaptive Control

Basic flow for designing an adaptive controller

1. Design a control law with variable parameters

2. Design an adaptation law for adjusting the control parameters

3. Analyze the convergence of the closed-loop system 

The control law design at the first step typically requires the designer to know what a good controller is if the true parameters were actually known, e.g., from feedback linearization (Appendix \@ref(feedbacklinearization)), sliding control (Appendix \@ref(slidingcontrol)) etc. 

The design of the adaptation law typically comes from analyzing the dynamics of the tracking error, which as we will see often appears in the form of Lemma \@ref(lem:adaptivecontrolbasic).

The convergence of the closed-loop system is usually analyzed with the help of a Lyapunov-like function introduced in Chapter \@ref(stability).

::: {.lemma #adaptivecontrolbasic name="Basic Lemma"}
Let two signals $e(t)$ and $\phi(t)$ be related by 
\begin{equation}
e(t) = H(p)[k \phi(t)^T v(t)]
(\#eq:acbasiclemmaephi)
\end{equation}
where $e(t)$ a scalar output signal, $H(p)$ a strictly positive real (SPR) transfer function, $k$ an unknown real number with known sign, $\phi(t) \in \mathbb{R}^m$ a control signal, and $v(t) \in \mathbb{R}^m$ a measurable input signal.

If the control signal $\phi(t)$ satisfies
\begin{equation}
\dot{\phi}(t) = - \mathrm{sgn}(k) \gamma e(t) v(t)
(\#eq:acbasiclemmaphilaw)
\end{equation}
with $\gamma > 0$ a positive constant, then $e(t)$ and $\phi(t)$ are globally bounded. Moreover, if $v(t)$ is bounded, then 
$$
\lim_{t \rightarrow \infty} e(t) = 0.
$$
:::
::: {.proof}
Let the state-space representation of \@ref(eq:acbasiclemmaephi) be
\begin{equation}
\dot{x} = A x + b [k \phi^T v], \quad e = c^T x.
(\#eq:acbasiclemmastatespace)
\end{equation}
Since $H(p)$ is SPR, it follows from the Kalman-Yakubovich Lemma \@ref(lem:KalmanYakubovich) that there exist $P,Q \succ 0$ such that 
$$
A^T P + P A = -Q, \quad Pb = c.
$$
Let 
$$
V(x,\phi) = x^T P x + \frac{|k|}{\gamma} \phi^T \phi,
$$
clearly V is positive definite (i.e., $V(0,0)=0$, and $V(x,\phi) > 0$ for all $x \neq 0, \phi \neq 0$). The time derivative of $V$ along the trajectory defined by \@ref(eq:acbasiclemmastatespace) with $\phi$ chosen as in \@ref(eq:acbasiclemmaphilaw) is 
\begin{align}
\dot{V} & = \frac{\partial V}{\partial x} \dot{x} + \frac{\partial V}{\partial \phi} \dot{\phi} \\
&= x^T (PA + A^T P) x + 2 x^T P b (k \phi^T v) + \frac{2|k|}{\gamma} \phi^T (- \mathrm{sgn}(k) \gamma e v) \\
& = - x^T Q x + 2 (x^T c)(k\phi^T v) - 2 \phi^T (e v) \\
& = - x^T Q x \leq 0.
\end{align}
As a result, we know $x$ and $\phi$ must be bounded ($V(x(t),\phi(t)) \leq V(x(0),\phi(0))$ is bounded). Since $e = c^T x$, we know $e$ must be bounded as well.

If the input signal $v$ is also bounded, then $\dot{x}$ is bounded as seen from \@ref(eq:acbasiclemmastatespace). Because $\ddot{V} = -2x^T Q \dot{x}$ is now bounded, we know $\dot{V}$ is uniformly continuous. Therefore, by Barbalat's stability certificate (Theorem \@ref(thm:BarbalatStability)), we know $\dot{V}$ tends to zero as $t$ tends to infinity, which implies $\lim_{t \rightarrow \infty} x(t) = 0$ and hence $\lim_{t \rightarrow \infty} e(t) = 0$.
:::

### First-Order Systems
<!-- ### Linear Systems  -->
Consider the first-order single-input single-output (SISO) system 
\begin{equation}
\dot{x} = - a x + b u
(\#eq:ac-first-linear)
\end{equation}
where $a$ and $b$ are unknown groundtruth parameters. However, we do assume that the sign of $b$ is known. <span style="color:red">What if the sign of $b$ is unknown too?</span>

Let $r(t)$ be a reference trajectory, e.g., a step function or a sinusoidal function, and $x_d(t)$ be a desired system trajectory that tracks the reference
\begin{equation}
\dot{x}_d = - a_d x_d + b_d r(t),
(\#eq:ac-first-linear-desired)
\end{equation}
where $a_d,b_d > 0$ are user-defined constants. Note that the transfer function from $r$ to $x_d$ is 
$$
x_d = \frac{b_d}{p + a_d} r
$$
and the system is stable. <span style="color:red">Review basics of transfer function.</span>

The goal of adaptive control is to design a control law and an adaptation law such that the tracking error of the system $x(t) - x_d(t)$ converges to zero. 

**Control law**. We design the control law as 
\begin{equation}
u = \hat{a}_r(t) r + \hat{a}_x(t) x 
(\#eq:ac-first-linear-control)
\end{equation}
where $\hat{a}_r(t)$ and $\hat{a}_x(t)$ are time-varying feedback gains that we wish to adapt. The closed-loop dynamics of system \@ref(eq:ac-first-linear) with the controller \@ref(eq:ac-first-linear-control) is
$$
\dot{x} = - a x + b (\hat{a}_r r + \hat{a}_x x) = - (a - b \hat{a}_x) x + b \hat{a}_r r. 
$$
With the equation above,
the reason for choosing the control law \@ref(eq:ac-first-linear-control) is clear: if the system parameters $(a,b)$ were known, then choosing 
\begin{equation}
a_r^\star = \frac{b_d}{b}, \quad a_x^\star = \frac{a - a_d}{b}
(\#eq:ac-first-linear-optimal-gain)
\end{equation}
leads to the closed-loop dynamics $\dot{x} = - a_d x + b_d r$ that is exactly what we want in \@ref(eq:ac-first-linear-desired). 

However, in adaptive control, since the true parameters $(a,b)$ are not revealed to the control designer, an adaptation law is needed to dynamically adjust the gains $\hat{a}_r$ and $\hat{a}_x$ based on the tracking error $x(t) - x_d(t)$. 

**Adaptation law**. Let $e(t) = x(t) - x_d(t)$ be the tracking error, and we develop its time derivative
\begin{align}
\dot{e} &= \dot{x} - \dot{x}_d \\
        &= - a_d (x - x_d) + (a_d - a + b\hat{a}_x)x + (b \hat{a}_r - b_d) r \\
        & = - a_d e + b\underbrace{(\hat{a}_x - \hat{a}_x^\star)}_{=:\tilde{a}_x} x + b \underbrace{(\hat{a}_r - \hat{a}_r^\star )}_{=:\tilde{a}_r} r \\
        & = - a_d e + b (\tilde{a}_x x + \tilde{a}_r r) (\#eq:ac-first-linear-error-dynamics)
\end{align}
where $\tilde{a}_x$ and $\tilde{a}_r$ are the gain errors w.r.t. the optimal gains in \@ref(eq:ac-first-linear-optimal-gain) if the true parameters were known. The error dynamics \@ref(eq:ac-first-linear-error-dynamics) is equivalent to the following transfer function 
\begin{equation}
e = \frac{1}{p + a_d} b(\tilde{a}_x x + \tilde{a}_r r) = \frac{1}{p + a_d} \left(b 
\begin{bmatrix} \tilde{a}_x \\ \tilde{a}_r \end{bmatrix}^T 
\begin{bmatrix} x \\ r \end{bmatrix}
\right),
(\#eq:ac-first-linear-error-dynamics-transfer)
\end{equation}
which is in the form of \@ref(eq:acbasiclemmaephi). Therefore, we choose the adaptation law 
\begin{equation}
\begin{bmatrix} \dot{\tilde{a}}_x \\ \dot{\tilde{a}}_r \end{bmatrix} = - \mathrm{sgn}(b) \gamma e \begin{bmatrix} x \\ r \end{bmatrix}.
(\#eq:ac-first-linear-adaptation-law)
\end{equation}

**Tracking convergence**. With the control law \@ref(eq:ac-first-linear-control) and the adaptation law \@ref(eq:ac-first-linear-adaptation-law), we can prove that the tracking error converges to zero, using Lemma \@ref(lem:adaptivecontrolbasic). With $\tilde{a}=[\tilde{a}_x, \tilde{a}_r]^T$, let 
$$
V(e,\tilde{a}) = e^2 + \frac{|b|}{\gamma} \tilde{a}^T \tilde{a}
$$
be a positive definite Lyapunov function candidate with time derivative
$$
\dot{V} = - 2a_d e^2 \leq 0.
$$
Clearly, $e$ and $\tilde{a}$ are both bounded. Assuming the reference trajectory $r$ is bounded, we know $x_d$ is bounded (due to \@ref(eq:ac-first-linear-desired)) and hence $x$ is bounded (due to $e = x - x_d$ being bounded). Consequently, from the error dynamics \@ref(eq:ac-first-linear-error-dynamics) we know $\dot{e}$ is bounded, which implies $\ddot{V} = -4a_d e \dot{e}$ is bounded and $\dot{V}$ is uniformly continuous. By Barbalat's stability certificate \@ref(thm:BarbalatStability), we conlude $e(t) \rightarrow 0$ as $t \rightarrow \infty$. 

It is always better to combine mathematical analysis with intuitive understanding. Can you explain intuitively why the adaptation law \@ref(eq:ac-first-linear-adaptation-law) makes sense? (Hint: think about how the control should react to a negative/positive tracking error.)

**Parameter convergence**. We have shown the control law \@ref(eq:ac-first-linear-control) and the adaptation law \@ref(eq:ac-first-linear-adaptation-law) guarantee to track the reference trajectory. However, is it guaranteed that the gains of the controller \@ref(eq:ac-first-linear-control) also converge to the optimal gains in \@ref(eq:ac-first-linear-optimal-gain)? 

We will now show that the answer is indefinite and it depends on the reference trajectory $r(t)$. Because the tracking error $e$ converges to zero, and $e$ is the output of a stable filter \@ref(eq:ac-first-linear-error-dynamics-transfer), we know the input $b(\tilde{a}_x x + \tilde{a}_r r)$ must also converge to zero. On the other hand, the adaptation law \@ref(eq:ac-first-linear-adaptation-law) shows that both $\dot{\tilde{a}}_x$ and $\dot{\tilde{a}}_r$ converge to zero (due to $e$ converging to zero and $x$, $r$ being bounded). As a result, we know $\tilde{a} = [\tilde{a}_x,\tilde{a}_r]^T$ converges to a constant that satisfies
\begin{equation}
v^T \tilde{a} = 0, \quad v = \begin{bmatrix} x \\ r \end{bmatrix},
(\#eq:ac-first-linear-parameter-equation)
\end{equation}
which is a single linear equation of $\tilde{a}$ with time-varying coeffients. 

- **Constant reference: no guaranteed convergence**. Suppose $r(t) \equiv r_0 \neq 0$ for all $t$. From \@ref(eq:ac-first-linear-desired) we know $x = x_d = \alpha r_0$ when $t \rightarrow \infty$, where $\alpha$ is the constant DC gain of the stable filter. Therefore, the linear equation \@ref(eq:ac-first-linear-parameter-equation) reduces to 
$$
\alpha \tilde{a}_x + \tilde{a}_r  = 0. 
$$
This implies that $\tilde{a}$ does not necessarily converge to zero. In fact, it converges to a straight line in the parameter space. 

- **Persistent excitation: guaranteed convergence**. However, when the signal $v$ satisfies the so-called _persistent excitation_ condition, which states that for any $t$, there exists $T, \beta > 0$ such that 
\begin{equation}
\int_{t}^{t+T} v v^T d\tau \geq \beta I,
(\#eq:ac-first-linear-persistent-excitation)
\end{equation}
then $\tilde{a}$ is guaranteed to converge to zero. To see this, we multiply \@ref(eq:ac-first-linear-parameter-equation) by $v$ and integrate it from $t$ to $t+T$, which gives rise to
$$
\left( \int_{t}^{t+T} vv^T d\tau \right) \tilde{a} = 0.
$$
By the persistent excitation condition \@ref(eq:ac-first-linear-persistent-excitation), we infer that $\tilde{a} = 0$ is the only solution. 

It remains to understand under what conditions of the reference trajectory $r(t)$ can we guarantee the persistent excitation of $v$. We leave it as an exercise for the reader to show, if $r(t)$ contains at least one sinusoidal component, then the persistent excitation condition of $v$ is guaranteed. 

<!-- ### Nonlinear Systems  -->
::: {.exercise #adaptivecontrolfirstordernonlinearsystem name="Extension to Nonlinear Systems"}
Design a control law and an adaptation law for the following system
$$
\dot{x} = - a x - c f(x) + b u
$$
with unknown true parameters $(a,b,c)$ (assume the sign of $b$ is known) and known nonlinearity $f(x)$ to track a reference trajectory $r(t)$. Analyze the convergence of tracking error and parameter estimation error.
:::

### High-Order Systems
Consider an $n$-th order nonlinear system
\begin{equation}
q^{(n)} + \sum_{i=1}^n \alpha_i f_i(x,t) = bu
(\#eq:ac-singleinput-nonlinear)
\end{equation}
where $x=[q,\dot{q},\ddot{q},\dots,q^{(n-1)}]^T$ is the state of the system, $f_i$'s are known nonlinearities, $(\alpha_1,\dots,\alpha_n,b)$ are unknown parameters of the system (with $\mathrm{sgn}(b)$ known). 

The goal of adaptive control is to control the system \@ref(eq:ac-singleinput-nonlinear) trajectory to follow a desired trajectory $q_d(t)$ despite no knowing the true parameters.

To facilitate the derivation of the adaptive controller, let us divide both sides of \@ref(eq:ac-singleinput-nonlinear) by $b$
\begin{equation}
h q^{(n)} + \sum_{i=1}^n a_i f_i(x,t) = u
(\#eq:ac-singleinput-nonlinear-equivalent)
\end{equation}
where $h = 1 / b$ and $a_i = \alpha_i / b$. 

**Control law**. Recall that the choice of the control law is tyically inspired by the control design if the true system parameters were known. We will borrow ideas from sliding control (Appendix \@ref(slidingcontrol)). 

- **Known parameters**. Let $e = q(t) - q_d(t)$ be the tracking error, and define the following combined error 
$$
s = e^{(n-1)} + \lambda_{n-2} e^{(n-2)} + \dots + \lambda_0 e = \Delta(p) e 
$$
where $\Delta(p) = p^{n-1} + \lambda_{n-2} p^{(n-2)} + \dots + \lambda_0$ is a stable polynomial with user-chosen coeffients $\lambda_0,\dots,\lambda_{n-2}$. The rationale for defining the combined error $s$ is that the convergence of $e$ to zero can be guaranteed by the convergence of $s$ to zero (when $\Delta(p)$ is stable).
Note that $s$ can be equivalently written as 
\begin{align}
s & = (q^{(n-1)} - q_d^{(n-1)}) + \lambda_{n-2} e^{(n-2)} + \dots + \lambda_0 e \\
& = q^{(n-1)} - \underbrace{ \left( q_d^{(n-1)} - \lambda_{n-2} e^{(n-2)} - \dots - \lambda_0 e  \right) }_{q_r^{(n-1)}}.
\end{align}
Now consider the control law 
\begin{equation}
u = h q_r^{(n)} - ks + \sum_{i=1}^n a_i f_i(x,t)
(\#eq:ac-singleinput-nonlinear-control-law-knownparam)
\end{equation}
where 
$$
q_r^{(n)} = q_d^{(n)} - \lambda_{n-2} e^{(n-1)} - \dots - \lambda_0 \dot{e}
$$
and $k$ is a design constant that has the same sign as $h$. This choice of control, plugged into the system dynamics \@ref(eq:ac-singleinput-nonlinear-equivalent), leads to 
\begin{align}
h q^{(n)} + \sum_{i=1}^n a_i f_i(x,t) = h q_r^{(n)} - ks + \sum_{i=1}^n a_i f_i(x,t) \Longleftrightarrow \\
h \left( q^{(n)} - q_r^{(n)} \right) + ks = 0 \Longleftrightarrow \\
h \dot{s} + ks = 0,
\end{align}
which guarantees the exponential convergence of $s$ to zero (note that $h$ and $k$ have the same sign), and hence the convergence of $e$ to zero. 

- **Unknown parameters**. Inspired by the control law with known parameters in \@ref(eq:ac-singleinput-nonlinear-control-law-knownparam), we design the adapative control law as 
\begin{equation}
u = \hat{h} q_r^{(n)} - ks + \sum_{i=1}^n \hat{a}_i f_i(x,t),
(\#eq:ac-singleinput-nonlinear-control-law-unknownparam)
\end{equation}
where the time-varying gains $\hat{h},\hat{a}_1,\dots,\hat{a}_n$ will be adjusted by an adaptation law. 

**Adaptation law**. Inserting the adapative control law \@ref(eq:ac-singleinput-nonlinear-control-law-unknownparam) into the system dynamics \@ref(eq:ac-singleinput-nonlinear-equivalent), we obtain
\begin{align}
h \dot{s} + ks = \tilde{h} q_r^{(n)} + \sum_{i=1}^n \tilde{a}_i f_i (x,t) \Longleftrightarrow \\
s = \frac{1}{p + k/h} \frac{1}{h} \underbrace{ \left( 
    \begin{bmatrix} \tilde{h} \\ \tilde{a}_1 \\ \vdots \\ \tilde{a}_n \end{bmatrix}^T
    \begin{bmatrix} q_r^{(n)} \\ f_1(x,t) \\ \vdots \\ f_n(x,t) \end{bmatrix}
    \right)}_{=:\phi^T v}
(\#eq:ac-singleinput-nonlinear-error-dynamics)
\end{align}
where $\tilde{h} = \hat{h} - h$ and $\tilde{a}_i = \hat{a}_i - a_i,i=1,\dots,n$. Again, \@ref(eq:ac-singleinput-nonlinear-error-dynamics) is in the familiar form of \@ref(eq:acbasiclemmaephi), which naturally leads to the following adaptation law with $\gamma > 0$ a chosen constant
\begin{equation}
\dot{\phi} = \begin{bmatrix} \dot{\tilde{h}} \\ \dot{\tilde{a}}_1 \\ \vdots \\ \dot{\tilde{a}}_n \end{bmatrix} = - \mathrm{sgn}(h) \gamma s \begin{bmatrix} q_r^{(n)} \\ f_1(x,t) \\ \vdots \\ f_n(x,t) \end{bmatrix}.
(\#eq:ac-singleinput-nonlinear-adaptation-law)
\end{equation}

**Tracking and parameter convergence**. With the following Lyapunov function 
$$
V(s,\phi) = |h| s^2 + \frac{1}{\gamma} \phi^T \phi, \quad \dot{V}(s,\phi) -2|k| s^2,
$$
the global convergence of $s$ to zero can be easily shown. For parameter convergence, it is easy to see that when $v$ satisfies the persistent excitation condition, we have that $\phi$ converges to zero. (However, the relationship between the reference trajectory $q_d(t)$ and the persistent excitation of $v$ becomes nontrivial due to the nonlinearities $f_i$.)




## Certainty-Equivalent Adaptive Control



