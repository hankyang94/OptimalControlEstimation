# Problem Sets {#psets}

::: {.exercisebox}
::: {.exercise #polygoninsidecircle name="Inscribed Polygon of Maximal Perimeter"}
In this exercise, we will use dynamic programming to solve a geometry problem, i.e., to find the $N$-side polygon inscribed inside a circle with maximum perimeter. We will walk you through the key steps of formulating and solving the problem, while leaving a few mathematical details for you to fill in.

Given a circle with radius $1$, we can randomly choose $N$ distinct points on the circle to form a polygon with $N$ vertices and sides, as shown in Fig. \@ref(fig:inscribed-polygon) with $N=3,4,5$.

```{r inscribed-polygon, out.width='80%', fig.show='hold', fig.cap='Polygons inscribed inside a circle', fig.align='center', echo=FALSE}
knitr::include_graphics('images/polygon-inside-circle.png')
```

Once the $N$ points are chosen, the $N$-polygon will have a perimeter, i.e., the sum of the lengths of its edges. 

What is the configuration of the $N$ points such that the resulting $N$-polygon has the maximum perimeter? I claim that the answer is when the $N$-polygon has edges of equal lengths, or in other words, when the $N$ points are placed on the circle evenly. 

Let us use dynamic programming to prove the claim.

To use dynamic programming, we need to definie a dynamical system and an objective function.

```{r sequential-placement-N-point, out.width='50%', fig.show='hold', fig.cap='Sequential placement of N points on the circle.', fig.align='center', echo=FALSE}
knitr::include_graphics('images/sequential-placement-N-point.png')
```

**Dynamical system**. We will use $\{x_1,\dots,x_N \}$ to denote the angular positions of the $N$ points to be placed on the circle (with slight abuse of notation, we will call each of those points $x_k$ as well). In particular,
as shown in Fig. \@ref(fig:sequential-placement-N-point), let us use $x_k$ to denote the angle between the line $O-x_k$ and the vertical line ($O$ is the center of the circle), with zero angle starting at $12$ O'clock and clockwise being positive. Without loss of generality, we assume $x_1 = 0$. (if $x_1$ is nonzero, we can always rotate the entire circle so that $x_1 = 0$). 

After the $k$-th point is placed, we can "control" where the next point $x_{k+1}$ will be, by deciding the incremental angle between $x_{k+1}$ and $x_k$, denoted as $u_k > 0$ in Fig. \@ref(fig:sequential-placement-N-point). This is simply saying the dynamics is
$$
x_{k+1} = x_k + u_k, \quad k=1,\dots,N-1, \quad x_1 = 0.
$$

**Cost-to-go**. The perimeter of the $N$-polygon is therefore
$$
g_N(x_N) + \sum_{k=1}^{N-1} g_k(x_k, u_k),
$$
with the terminal cost
$$
g_N(x_N) = 2 \sin \left(  \frac{2\pi - x_N}{2} \right)
$$
the distance between $x_N$ and $x_1$ (see Fig. \@ref(fig:sequential-placement-N-point)), and the running cost
$$
g_k(x_k,u_k) = 2 \sin \left(  \frac{u_k}{2} \right)
$$
the distance between $x_{k+1}$ and $x_k$. 

**Dynamic programming**. We are now ready to invoke dynamic programming.

We start by setting
$$
J_N(x_N) = g_N(x_N) = 2 \sin \left(  \frac{2\pi - x_N}{2} \right).
$$
We then compute $J_{N-1}(x_{N-1})$ as 
\begin{equation}
J_{N-1}(x_{N-1}) = \max_{0< u_{N-1} < 2\pi - x_{N-1}} \left\{ \underbrace{ 2 \sin \left(  \frac{u_{N-1}}{2} \right) + J_N(x_{N-1} + u_{N-1}) }_{Q_{N-1}(x_{N-1}, u_{N-1})} \right\},
(\#eq:polygon-circle-N-1)
\end{equation}
where $u_{N-1} < 2\pi - x_{N-1}$ because we do not want $x_N$ to cross $2\pi$.

a. Show that
$$
Q_{N-1}(x_{N-1},u_{N-1}) = 2 \sin \left(  \frac{u_{N-1}}{2} \right) + 2 \sin \left(  \frac{2\pi - x_{N-1} - u_{N-1} }{2} \right),
$$
and 
$$
\frac{\partial Q_{N-1}(x_{N-1},u_{N-1})}{\partial u_{N-1}} = \cos \left(  \frac{u_{N-1}}{2} \right) -  \cos \left(  \frac{2\pi - x_{N-1} - u_{N-1} }{2} \right).
$$

b. Show that $Q_{N-1}(x_{N-1},u_{N-1})$ is concave (i.e., $-Q_{N-1}(x_{N-1},u_{N-1})$ is convex) in $u_{N-1}$ for every $x_{N-1} \in (0, \pi)$ and $u_{N-1} \in (0, 2\pi - x_{N-1})$. (Hint: compute the second derivative of $Q_{N-1}(x_{N-1},u_{N-1})$ with respect to $u_{N-1}$ and use Proposition \@ref(prp:decidecvx)).

c. With a and b, show that the optimal $u_{N-1}$ that solves \@ref(eq:polygon-circle-N-1) is
$$
u_{N-1}^\star = \frac{2\pi - x_{N-1}}{2},
$$
and therefore
$$
J_{N-1}(x_{N-1}) = 4 \sin \left( \frac{2\pi - x_{N-1}}{4} \right).
$$
(Hint: the point at which a concave function's gradient vanishes must be the unique maximizer of that function)

d. Now use induction to show that the $k$-th step dynamic programming
$$
J_k(x_k) = \max_{0< u_k < 2\pi - x_k} \left\{ 2 \sin\left( \frac{u_k}{2} \right) + J_{k+1}(x_k + u_k) \right\}
$$
admits an optimal control
$$
u_k^\star = \frac{2\pi - x_k}{N-k+1},
$$
and optimal cost-to-go
$$
J_k(x_k) = 2(N-k+1)\sin\left( \frac{2\pi - x_k}{2(N-k+1)} \right).
$$

e. Starting from $x_1 = 0$, what is the optimal sequence of controls? 

Hopefully now you see why my original claim is true!

**(Bonus)** We are not yet done for this exercise. Since you have probably already spent quite some time on this exercise, I will leave the rest of the exercise a bonus. In case you found this simple geometric problem interesting, you should keep reading as we will use numerical techniques to prove the same claim.

In Fig. \@ref(fig:sequential-placement-N-point), by denoting 
$$
u_N = 2\pi - x_N = 2\pi - (u_1 + \dots + u_{N-1})
$$
as the angle between the line $O-x_{N}$ and the line $O-x_1$, it is not hard to observe that the perimeter of the $N$-polygon is 
$$
\sum_{k=1}^N 2 \sin \left( \frac{u_k}{2} \right).
$$
Consequently, to maximize the perimeter, we can formulate the following optimization
\begin{equation}
\begin{split}
\max_{u_1,\dots,u_N} &\quad \sum_{k=1}^N 2 \sin \left( \frac{u_k}{2} \right) \\
\text{subject to} &\quad u_k > 0, k=1,\dots,N \\
&\quad u_1 + \dots + u_N = 2 \pi
\end{split}
(\#eq:polygon-circle-convexoptmization)
\end{equation}
where $u_k$ can be seen as the angle spanned by the line $x_k - x_{k+1}$ with respect to the center $O$ so that they are positive and sum up to $2\pi$.

f. Show that the optimization \@ref(eq:polygon-circle-convexoptmization) is convex. (Hint: first show the feasible set is convex, and then show the objective function is concave over the feasible set.)

Now that we have shown \@ref(eq:polygon-circle-convexoptmization) is a convex optimization problem, we know that pretty much any numerical algorithm will guarantee convergence to the globally optimal solution.

It is too much to ask you to implement a numerical algorithm on your own, as that can be a one-semester graduate-level course [@nocedal99book-numerical]. However, Matlab provides a nice interface, [`fmincon`](https://www.mathworks.com/help/optim/ug/fmincon.html), to many such numerical algorithms, and let me show you how to use `fmincon` to solve \@ref(eq:polygon-circle-convexoptmization) so we can numerically prove our claim.

g. I have provided most of the code necessary for solving \@ref(eq:polygon-circle-convexoptmization) below. Please fill in the definition of the function `perimeter(u)`, and then run the code in Matlab. Show your results for $N=3,10,100$. Do the solutions obtained from `fmincon` verify our claim?

```matlab
clc; clear; close all;
% number of points to be placed
N = 10;
% define the objective function
% fmincon assumes minimization
% We minimize the negative perimeter so as to maximize the perimeter
objective = @(u) -1*perimeter(u);
% choose which algorithm to use for solving
options = optimoptions('fmincon', 'Algorithm', 'interior-point');
% supply an initial guess
% since this is a convex problem, we can use any initial guess
u0 = rand(N,1);
% solve
uopt = fmincon(objective,u0,... % objective and initial guess
    -eye(N),zeros(N,1),... % linear inequality constraints
    ones(1,N),2*pi,... % linear equality constraints
    [],[],[],... % we do not have lower/upper bounds and nonlinear constraints
    options);

% plot the solution
x = zeros(N,1);
for k = 2:N
    x(k) = x(k-1) + uopt(k-1);
end
figure;
% plot a circle
viscircles([0,0],1);
hold on
% scatter the placed points
scatter(cos(x),sin(x),'blue','filled');
axis equal;

%% helper functions
% The objective function
function f = perimeter(u)
% TODO: define the perimeter function here.
end
```
:::
:::

&nbsp;

::: {.exercisebox}
::: {.exercise #lqrconstraints name="LQR with Constraints"}

In class we worked on the LQR problem where the states and controls are unbounded. This is rarely the case in real life -- you only have a limited amount of control power, and you want your states to be bounded (e.g., not entering some dangerous zones). 

For linear systems with convex constraints on the control and states, the seminal paper [@bemporad02automatica-explicit] investigates the landscape of the optimal cost-to-go and controller. 

In this exercise, let us use convex optimization to numerically study a toy problem.

Consider a variant of the LQR problem \@ref(eq:lqr-formulation) where the controls are bounded between $[-u_{\max}, u_{\max}]$, the system matrices $A_k, B_k$ are constant, and the dynamics is deterministic:
\begin{equation}
\begin{split}
J(x_0) = \min_{u_{0},\dots,u_{N-1} \in [-u_{\max},u_{\max}]} &\quad  x_N^T Q_N x_N + \sum_{k=0}^{N-1} (x_k^T Q_k x_k + u_k^T R_k u_k) \\
\text{subject to} &\quad  x_{k+1} = A x_k + B u_k,  k=0,\dots,N-1
\end{split}
(\#eq:lqr-constraints)
\end{equation}
We assume $Q_k\succeq 0$ for $k=0,\dots,N$ and $R_k \succ 0$ for all $k=0,\dots,N-1$.

a. Show that Problem \@ref(eq:lqr-constraints), when $x_0$ is given, is a convex optimization problem.

b. Discretize the continuous-time double integrator dynamics
$$
\ddot{q} = u, \quad u \in [-1,1]
$$
in the form of $x_{k+1} = A x_k + B u_k$ with a constant $dt$ time discretization. (Hint: take $x = [q,\dot{q}]$ as the state vector.)

c. Fix $N=50$, $dt=0.1$ and choose your favorite $Q_k$ and $R_k$. Solve the convex optimization \@ref(eq:lqr-constraints) at a dense grid of $x_0$ (e.g., using CVX or cvxpy). Plot the optimal cost-to-go $J(x_0)$, and the optimal controls $u_0(x_0),\dots,u_{N-1}(x_0)$. For the optimal controls, you can just plot one of the controls such as $u_0(x_0)$. You may want to use the Matlab function [`surf`](https://www.mathworks.com/help/matlab/ref/surf.html). (Hint: you will most likely benefit from Appendix \@ref(appconvex-practice).)

d. Increase $N$ and decrease $dt$, repeat (c). Do you get more fine-grained plots of the optimal cost-to-go and controls? (When you increase $N$, the convex optimization has more variables to optimize, so there is a limit at which the solver takes too much time.)

e. **(Bonus)** We only have constraints on the control so far. What if you add constraints to the states as well? For example, you can try limiting the velocity $\dot{q}$ to be at least $0.1$ by adding $\dot{q}_k \geq 0.1$ for some k. How will $J$ and $u$ change?

e. **(Bonus)** Can you write down the KKT optimality conditions of \@ref(eq:lqr-constraints) and explain what you have observed from the numerical experiments? (Hint: KKT optimality conditions can be found in Theorem \@ref(thm:KKT).)
:::
:::

&nbsp;

::: {.exercisebox}
::: {.exercise #cartpole name="Cart Pole System"}

In this exercse, let us study the cart-pole system (we saw the video of human-controlled version in our first lecture), another interesting nonlinear control problem, and reinforce our knowledge about LQR.

Our task is to balance a pendulum on a cart by horizontally moving the cart. Fig. \@ref(fig:cart-pole) gives an illustration of the system. See this [video](https://www.youtube.com/watch?v=Bzq96V1yN5k) for an actual robotic implementation. 

```{r cart-pole, out.width='60%', fig.show='hold', fig.cap='Illustration of cart-pole problem', fig.align='center', echo=FALSE}
knitr::include_graphics('images/cartpole.png')
```

With the above illustration, we parameterize the system with two scalars: $x$ represents the current location of the cart, while $\theta$ is the angle between current pole and the stable equilibrium. Therefore, our goal is to study the motion of the cart-pole system with a horizonal control $f$. We assume hereafter the system is ideal such that there is no friction, and the mass of the pole concentrates at the free end point. 

a. **(Bonus)** For those of you who have background in rigid-body dynamics, this is an opportunity for you to apply your knowledge. However, feel free to skip this subproblem and it won't affect the rest of the exercise. 
Denote the mass of cart and pole as $m_c$ and $m_p$, respectively. Derive the equations of motion:
\begin{equation}
\left(m_c+m_p\right) \ddot{x}+m_p l \ddot{\theta} \cos \theta-m_p l \dot{\theta}^2 \sin \theta=f,
(\#eq:ex-cartpole-1)
\end{equation}
\begin{equation}
m_p l \ddot{x} \cos \theta+m_p l^2 \ddot{\theta}+m_p g l \sin \theta=0.
(\#eq:ex-cartpole-2)
\end{equation}
(Hints: compute the Lagrangian of the system and the corresponding Lagrangian equations. Analyzing the two objects separately also works.)
  <!--Hint2: https://en.wikipedia.org/wiki/Lagrangian_mechanics#Pendulum_on_a_movable_support-->
    
<!-- (ii) Translate the equations \@ref(eq:ex-cartpole-1) and \@ref(eq:ex-cartpole-2) into the standard form 
\begin{equation}
\mathbf{M}(\mathbf{q}) \ddot{\mathbf{q}}+\mathbf{C}(\mathbf{q}, \dot{\mathbf{q}}) \dot{\mathbf{q}}=\tau_g(\mathbf{q})+\mathbf{B u},
\end{equation}
where $\mathbf{q}=\begin{bmatrix}x\\ \theta \end{bmatrix}$, $\mathbf{u}=\begin{bmatrix} f \end{bmatrix}$. What are $\mathbf{M},\mathbf{C}, \tau_g,\mathbf{B}$ here? -->
    
b. Translate the equations in (a) into the basic state-space dynamics form 
\begin{equation}
\dot{\mathbf{x}}=f(\mathbf{x}, \mathbf{u}).
(\#eq:ex-cartpole-3)
\end{equation}
What are $\mathbf{x},\mathbf{u},f$ here?
(Hint: try $\mathbf{x}=[x,\theta,\dot{x},\dot{\theta}]^\top$.)

c. Linearize the dynamics in (b) around the unstable equilibrium where $\theta^*=\pi$ and $x^*=\dot{x}^*=\dot{\theta}^*=0.$ (i.e., the pole is in the upright position and the cart stay at zero.) The result should be in the form of 
\begin{equation}
\dot{\Delta\mathbf{x}}=A\Delta\mathbf{x}+B\Delta\mathbf{u},
(\#eq:ex-cartpole-4)
\end{equation}
where $\Delta\mathbf{x} = \mathbf{x}-\mathbf{x}^*$ and $\Delta\mathbf{u}=\mathbf{u}-\mathbf{u}^*$.

d. Define the linearization error $e(\mathbf{x}, \mathbf{u}):=\|f(\mathbf{x}, \mathbf{u}) - (A\Delta\mathbf{x}+B\Delta\mathbf{u})\|^2$. Simulate the original system \@ref(eq:ex-cartpole-3) and the linearized system \@ref(eq:ex-cartpole-4) with the same initial condition. How does the linearization error change over time? Provide at least three different initialization results.<br>
(Hints: (i) Sanity check: intuitively the error should not depend on the initial location $x$, and it should have symmetry. Is that true in your simulation? <br>(ii) In the same unstable position, how does push/pull (positive/negative) force change the results?)

e. Convert the continuous-time dynamics in \@ref(eq:ex-cartpole-4) to discrete-time with a fixed time-discretization. Then design an LQR controller to stabilize the cart-pole at the unstable equilibrium. Does the LQR controller succeed for all initial conditions you tested? (Hint: try several initial conditions where the end point of the pole is above or below the horizontal line.) You may want to take a look at the LQR example for the simple pendulum in Example \@ref(exm:lqr-pendulum-stabilization).

<!-- e. **(Bonus)** Will a linear controller (i.e., $f$ is linear in $\mathbf{x}$) be a good controller? Why or why not? The answer might depend on whether the end point of the pole is above the horizonal line. -->
:::
:::

&nbsp;

::: {.exercisebox}
::: {.exercise #shooting-and-collocation name="Trajectory Optimization"}
Let us use this exercise to practice your skills in implementing trajectory optimization.

Consider a dynamical system
$$
x = \begin{bmatrix}
x_1 \\ x_2
\end{bmatrix}, \quad \dot{x} = f(x,u) = \begin{bmatrix}
(1-x_2^2)x_1 - x_2 + u \\
x_1 
\end{bmatrix}, \quad x(0) = x_0 = \begin{bmatrix} 0 \\ 1 \end{bmatrix}.
$$

With $T=10$, consider the following optimal control problem 
\begin{equation}
\begin{split}
\min_{u(t),t \in [0,T]} & \quad \int_{t=0}^T \Vert x(t) \Vert^2 + u(t)^2 dt \\
\text{subject to} & \quad \dot{x} = f(x,u), \quad x(0) = x_0 \\
& \quad u(t) \in [-1,1],\forall t \in [0,T].
\end{split}
\end{equation}

a. Solve the problem using direct multiple shooting with $N=50$ time intervals.

b. Solve the problem using direct collocation with $N=50$. 

Plot the optimized control signal and resulting state trajectory for both a and b. You probably want to refer to the source codes of Example \@ref(exm:multiple-shooting-double-integrator) and \@ref(exm:collocation-double-integrator).

:::
:::



# Acknowledgement {-}