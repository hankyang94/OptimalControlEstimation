
# Output Feedback {#output-feedback}

Consider a continuous-time dynamical system
\begin{equation}
\begin{split}
\dot{x} &= f(x,u)  \\
y &= h(x,u)
\end{split} 
(\#eq:output-feedback-system)
\end{equation}
where $x(t) \in \mathbb{X} \subseteq \mathbb{R}^n$ the state of the system, $u(t) \in \mathbb{U} \subseteq \mathbb{R}^m$ the control (or input), $y(t) \in \mathbb{Y} \subseteq \mathbb{R}^{d}$ the output (i.e., measurement) of the state and control, and $f,g$ the evolution and measurement functions (which are sufficiently smooth).



## State Observer {#state-observer}

For the system \@ref(eq:output-feedback-system), let us denote 

- $X(x_0,t_0;t;u)$ the solution at time $t$ with input $u$ and initial condition $x_0$ at time $t_0$; when $t_0 = 0$, we write $X(x_0;t;u)$

- $Y(x_0,t_0;t;u)$ the output at time $t$ with input $u$ and initial condition $x_0$ at time $t_0$, i.e., $Y(x_0,t_0;t;u) = h(X(x_0,t_0;t;u), u(t))$; when $t_0 = 0$, we write $y_{x_0,u}(t)$; 

- $\mathcal{X}_0$ a subset of $\mathbb{X}$ containing the initial conditions we consider; for any $x_0 \in \mathcal{X}_0$, we write $\sigma^+_{\mathcal{X}}(x_0;u)$ the maximal time of existence of $X(x_0,\cdot;t;u)$ in a set $\mathcal{X}$

- $\mathcal{U}$ the set of all sufficiently many times differentiable inputs $u: [0,+\infty) \rightarrow \mathbb{U}$.

The problem of state observation is to produce an estimated state $\hat{x}(t)$ of the true state $X(x_0,t_0;t;u)$ based on knowledge about the system \@ref(eq:output-feedback-system) and information about the history of inputs $u_{[0,t]}$ and outputs $y_{[0,t]}$, so that $\hat{x}(t)$ asymptotically converges to $X(x_0,t_0;t;u)$, for any initial condition $x_0 \in \mathcal{X}_0$ and any input $u \in \mathcal{U}$.

There are multiple ways for solving the problem of state observation (see e.g., [@bernard19book-observer], [@bernard22arc-observer]). Here we are particularly interested in the approach using a _state observer_, i.e., a dynamical system whose _internal state_ evolves according to the history of inputs and outputs, from which a state estimation can be reconstructed that guarantees asymptotic convergence to the true state. We formalize this concept below.

::: {.definition #stateobserver name="State Observer"}
A state observer for system \@ref(eq:output-feedback-system) is a couple $(\mathcal{F},\mathcal{T})$ such that 

1. $\mathcal{F}: \mathbb{R}^{l} \times \mathbb{R}^{m} \times \mathbb{R}^d \rightarrow \mathbb{R}^l$ is continuous

2. $\mathcal{T}$ is a family of continuous functions indexed by $u \in \mathcal{U}$ where each $\mathcal{T}_u: \mathbb{R}^l \times [0,+\infty) \rightarrow \mathbb{R}^n$ respects the causality condition
$$
\forall \tilde{u}: [0,+\infty) \rightarrow \mathbb{R}^m,\forall t \in [0,+\infty), u_{[0,t]} = \tilde{u}_{[0,t]} \Rightarrow  \mathcal{F}_u (\cdot,t) = \mathcal{F}_{\tilde{u}}(\cdot,t).
$$

3. For any $u \in \mathcal{U}$, any $z_0 \in \mathbb{R}^l$, and any $x_0 \in \mathcal{X}_0$ such that $\sigma^+_{\mathbb{X}}(x_0;u) = +\infty$, any solution $Z(z_0;t;u,y_{x_0,u})$^[We say "any solution" because there may be several solutions to the observer \@ref(eq:observer-definition-1) due to $\mathcal{F}$ only being continuous. This is not a problem as long as any such solution satisfies the required convergence property.] to 
\begin{equation}
\dot{z} = \mathcal{F}(z,u,y_{x_0,u})
(\#eq:observer-definition-1)
\end{equation} 
initialized at $z_0$ at time $0$ with input $u$ and $y_{x_0,u}$ exists on $[0,+\infty)$ and satisfies
\begin{equation}
\lim_{t \rightarrow \infty} \Vert \hat{X}(x_0,z_0;t;u) - X(x_0;t;u) \Vert = 0,
(\#eq:observer-definition-2)
\end{equation}
with 
\begin{equation}
\hat{X}(x_0,z_0;t;u) = \mathcal{T}_u(Z(z_0;t;u,y_{x_0,u}),t).
(\#eq:observer-definition-3)
\end{equation}
In words, (i) the state observer maintains an internal state (or latent state) $z \in \mathbb{R}^l$ that evolves according to the latent dynamics $\mathcal{F}$ in \@ref(eq:observer-definition-1), where $u$ and $y_{x_0,u}$ are inputs; (ii) an estimated state can be reconstructed from the internal state using $\mathcal{T}_u$ as in \@ref(eq:observer-definition-3); and (iii) the error between the estimated state and the true state (defined by a proper distance function $\Vert \cdot \Vert$ on $\mathbb{X}$) converges to zero.

If $\mathcal{T}_u$ is the same for any $u \in \mathcal{U}$ and is also time independent, then we say $\mathcal{T}$ is _stationary_.^[The time dependence of $\mathcal{T}_u$ enables us to cover the case where the knowledge of the $u$ and $y_{x_0,u}$ is used to construct the estimate from the observer state. In particular, using the output sometimes can reduce the dimension of the observer state (and thus alleviate the computations), thus obtaining a reduced-order observer. For example, see [@karagiannis05cdc-nonlinear] and [@astolfi03tac-immersion].] In this case, we can simply write the observer \@ref(eq:observer-definition-1) and \@ref(eq:observer-definition-3) as 
\begin{equation}
\begin{split}
\dot{z} &= \mathcal{F}(z,u,y) \\
\hat{x} &= \mathcal{T}(z).
\end{split}
(\#eq:observer-definition-simple)
\end{equation}

If $\hat{x}$ can be read off directly from $z$, then we say the observer \@ref(eq:observer-definition-simple) is _in the given coordinates_. A special case of this is when $\hat{x} = z$, i.e., the internal state of the observer is the same as the system state. 
:::

### General Design Strategy
::: {.theorembox}
::: {.theorem #observerdesignmeta name="Meta Observer"}
Let $F: \mathbb{R}^p \times \mathbb{R}^m \times \mathbb{R}^d \rightarrow \mathbb{R}^p$, $H: \mathbb{R}^p \times \mathbb{R}^m \rightarrow \mathbb{R}^d$ and $\mathcal{F}: \mathbb{R}^p \times \mathbb{R}^m \times \mathbb{R}^d \rightarrow \mathbb{R}^p$ be continuous functions such that 
\begin{equation}
\dot{\hat{\xi}} = \mathcal{F}(\hat{\xi}, u, \tilde{y})
(\#eq:meta-observer-zeta-hat)
\end{equation}
is an observer for 
\begin{equation}
\dot{\xi} = F(\xi,u,H(\xi,u)), \quad \tilde{y} = H(\xi,u),
(\#eq:meta-observer-zeta)
\end{equation}
i.e., for any $\xi_0,\hat{\xi}_0 \in \mathbb{R}^p$ and any $u \in \mathcal{U}$, the solution of the observer \@ref(eq:meta-observer-zeta-hat), 
denoted by $\hat{\Xi}(\hat{\xi}_0;t;u;\tilde{y}_{\xi_0,u})$, and the solution of the true system \@ref(eq:meta-observer-zeta), denoted by $\Xi(\xi_0;t;u)$, satisfy
\begin{equation}
\lim_{t \rightarrow \infty} \Vert \hat{\Xi}(\hat{\xi}_0;t;u;\tilde{y}_{\xi_0,u}) - \Xi(\xi_0;t;u) \Vert = 0.
(\#eq:meta-observer-zeta-converge)
\end{equation}
Note that the observer \@ref(eq:meta-observer-zeta-hat) is stationary and in the given coordinates for system \@ref(eq:meta-observer-zeta). Indeed the internal state of the observer is the same as the system state.

Now suppose for any $u \in \mathcal{U}$, there exists a continuous function (i.e., coordinate transformation) $T_u: \mathbb{R}^n \times \mathbb{R} \rightarrow \mathbb{R}^p$ and a subset $\mathcal{X}$ of $\mathbb{X}$ such that 

1. For any $x_0 \in \mathcal{X}_0$ such that $\sigma^+_{\mathbb{X}}(x_0;u) = + \infty$, $X(x_0;\cdot;u)$ remains in $\mathcal{X}$

2. There exists a concave $\mathcal{K}$^[A function $\rho: \mathbb{R}_+ \rightarrow \mathbb{R}_+$ is a $\mathcal{K}$ function if $\rho(0) = 0$, $\rho$ is continuous, and $\rho$ is increasing.] function $\rho$ and a positive number $\bar{t}$ such that 
$$
\Vert x_a - x_b \Vert \leq \rho (| T_u(x_a,t) - T_u(x_b,t) |), \quad \forall x_a,x_b \in \mathcal{X}, t \geq \bar{t},
$$
i.e., $x \mapsto T_u(x,t)$ becomes injective on $\mathcal{X}$,^[An injective function is a function $f$ that maps distinct elements of its domain to distinct elements. That is, $f(x_a) = f(x_b)$ implies $x_a = x_b$, or equivalently, $x_a \neq x_b$ implies $f(x_a) \neq f(x_b)$.] uniformly in time and space, after a certain time $\bar{t}$.

3. $T_u$ transforms the system \@ref(eq:output-feedback-system) into the system \@ref(eq:meta-observer-zeta), i.e., for all $x \in \mathcal{X}$ and all $t \geq 0$, we have
\begin{equation}
L_{(f,1)} T_u(x,t) = F(T_u(x,t),u,h(x,u)), \quad h(x,u) = H(T_u(x,t),u),
(\#eq:meta-observer-transform)
\end{equation}
where $L_{(f,1)} T_u(x,t)$ is the Lie derivative of $T_u$ along the vector field $(f,1)$
$$
L_{(f,1)} T_u(x,t) = \lim_{\tau \rightarrow 0} \frac{ T_u (X(x,t;t+\tau;u),t+\tau) - T_u(x,t) }{\tau}.
$$

4. $T_u$ respects the causality condition
$$
\forall \tilde{u}: [0,+\infty) \rightarrow \mathbb{R}^m, \forall t \in [0,+\infty), u_{[0,t]} = \tilde{u}_{[0,t]} \Rightarrow T_u(\cdot,t) = T_{\tilde{u}}(\cdot,t).
$$

Then, for any $u \in \mathcal{U}$, there exists a function $\mathcal{T}_u: \mathbb{R}^p \times [0,+\infty) \rightarrow \mathcal{X}$ (satisfying the causality condition) such that for any $t \geq \bar{t}$, $\xi \mapsto \mathcal{T}_u (\xi, t)$ is uniformly continuous on $\mathbb{R}^p$ and satisfies 
$$
\mathcal{T}_u \left( T_u(x,t),t \right) = x, \forall x \in \mathcal{X}.
$$
Moreover, denoting $\mathcal{T}$ the family of functions $\mathcal{T}_u$ for $u \in \mathcal{U}$, the couple $(\mathcal{F}, \mathcal{T})$ is an observer for the system \@ref(eq:output-feedback-system) initialized in $\mathcal{X}_0$.
:::
:::
::: {.proof}
See Theorem 1.1 in [@bernard19book-observer].
:::

A simpler version of Theorem \@ref(thm:observerdesignmeta) where the coordinate transformation $T_u$ is stationary and fixed for all $u$ is stated below as a corollary.

::: {.corollary #observerdesignmetafixedT name="Meta Observer with Fixed Transformation"}
Let $F: \mathbb{R}^p \times \mathbb{R}^m \times \mathbb{R}^d \rightarrow \mathbb{R}^p$, $H: \mathbb{R}^p \times \mathbb{R}^m \rightarrow \mathbb{R}^d$ and $\mathcal{F}: \mathbb{R}^p \times \mathbb{R}^m \times \mathbb{R}^d \rightarrow \mathbb{R}^p$ be continuous functions such that \@ref(eq:meta-observer-zeta-hat) is an observer for \@ref(eq:meta-observer-zeta). 

Suppose there exists a continuous coordinate transformation $T: \mathbb{R}^p \rightarrow \mathbb{R}^n$ and a compact subset $\Omega$ of $\mathbb{R}^n$ such that 

1. For any $x_0 \in \mathcal{X}_0$ such that $\sigma^+_{\mathbb{X}}(x_0;u) = + \infty$, $X(x_0;\cdot;u)$ remains in $\Omega$

2. $x \mapsto T(x)$ is injective on $\Omega$

3. $T$ transforms the system \@ref(eq:output-feedback-system) into system \@ref(eq:meta-observer-zeta)
$$
L_f T(x) = F(T(x),u,h(x,u)), \quad h(x,u) = H(T(x),u),
$$
where $L_f T(x)$ is the Lie derivative of $T(x)$ along $f$
$$
L_f T(x) = \lim_{\tau \rightarrow 0} \frac{ T(X(x,t;t+\tau;u))  - T(x)}{\tau}.
$$

Then, there exists a uniformly continuous function $\mathcal{T}:\mathbb{R}^p \rightarrow \mathbb{R}^{n}$ such that 
$$
\mathcal{T}(T(x)) = x, \quad \forall x \in \Omega,
$$
and $(\mathcal{F},\mathcal{T})$ is an observer for system \@ref(eq:output-feedback-system) initialized in $\mathcal{X}_0$.
:::

Theorem \@ref(thm:observerdesignmeta) and Corollary \@ref(cor:observerdesignmetafixedT) suggest the following general observer design strategy:

1. Find an injective coordinate transformation $T_u$ (that may be time-varying and also dependent on $u$) that transforms the original system \@ref(eq:output-feedback-system) with coordinate $x$ into a new system \@ref(eq:meta-observer-zeta) with coordinate $\xi$

2. Design an observer \@ref(eq:meta-observer-zeta-hat), $\hat{\xi}$, for the new system

3. Compute a left inverse, $\mathcal{T}_u$, of the transformation $T_u$ to recover a state estimation $\hat{x}$ of the original system.

The transformed systems \@ref(eq:meta-observer-zeta) are typically referred to as _normal forms_, or in my opinion, _templates_. 

Of course, the general design strategy is rather conceptual, and in order for it to be practical, we have to answer three questions.

- What templates do we have, what are their associated observers, and what are the conditions for the observers to be asymptotically converging?

- What kinds of (nonlinear) systems can be transformed into the templates, and how to perform the transformation?

- How to invert the coordinate transformation? Is it analytical or does it require numerical approximation?

In the following sections, we will study several representative normal forms and answer the above questions.

### Luenberger Template
Consider an instance of the normal form \@ref(eq:meta-observer-zeta) as follows:
\begin{equation}
\dot{\xi} = A \xi + B(u,y), \quad y = C \xi,
(\#eq:Luenberger-linear-template)
\end{equation}
where $A,C$ are constant matrices, and $B(u,y)$ can depend nonlinearly on $u$ and $y$.

For this template, we have the well-known Luenberger observer.

::: {.theorembox}
::: {.theorem #LuenbergerLinear name="Luenberger Observer"}
If the pair $(A,C)$ is detectable (see Theorem \@ref(thm:ltidetectable)), then there exists a matrix $K$ such that $A-KC$ is Hurwitz and the system 
\begin{equation}
\dot{\hat{\xi}} = A \hat{\xi} + B(u,y) + K(y - C \hat{\xi})
(\#eq:Luenberger-Linear)
\end{equation}
is an observer for \@ref(eq:Luenberger-linear-template).
:::
:::
::: {.proofbox}
::: {.proof}
Define $e(t) = \xi(t)  - \hat{\xi}(t)$. In that case,
\begin{equation}
    \dot{e}(t) = [A - KC] e(t)
    (\#eq:Luenberger-error)
\end{equation}

Solving \@ref(eq:Luenberger-error), we obtain

\begin{equation}
    e(t) = \mathrm{exp}[(A - KC)t] e(0)
\end{equation}

Then, if the real components of the eigenvalues of $A - KC$ are strictly negative (i.e., $A - KC$ is Hurwitz), then $e(t) \rightarrow 0$ as $t \rightarrow \infty$, independent of the initial error $e(0) = \xi(0) - \hat{\xi}(0)$. From Theorem \@ref(thm:ltidetectable), we know that $(A,C)$ being detectable implies the existence of $K$ such that $A - KC$ is Hurwitz.

If one is further interested in estimating the convergence rate of the Luenberger observer, then one can use the result from Corollary \@ref(cor:bestconvergencerate). Particularly, one can solve the Lyapunov equation
$$
(A - KC)^T P + P (A - KC) = - I
$$
to obtain $P$. Then the convergence rate of $\Vert e \Vert$ towards zero is $\frac{0.5}{\lambda_{\max}(P)}$.
:::
:::

The Luenberger observer is an elegant result in observer design (and even in control theory) that has far-reaching impact. In my opinion, the essence of observer design is twofold: (i) to simulate the dynamics when the state estimation is correct, and (ii) to correct the state estimation from observation when it is off. These two pieces of ideas are evident in \@ref(eq:Luenberger-Linear): the observer is a copy of the original dynamics ($A \hat{\xi} + B(u,y)$) plus a feedback correction from the difference between the "imagined" observation $C\hat{\xi}$ and the true observation $y$. 

You may think the Luenberger template is restricting because it requires the system to be linear (up to the only nonlinearly in $B(u,y)$). However, it turns out the Luenberger template is already quite useful, as I will show in the following pendulum example.

::: {.examplebox}
::: {.example #pendulumLuenberger name="Luenberger Observer for A Simple Pendulum"}
Consider a simple pendulum dynamics model
\begin{equation}
x = \begin{bmatrix}
\theta \\ \dot{\theta}
\end{bmatrix}, \quad 
\dot{x} = \begin{bmatrix} 
\dot{\theta} \\
- \frac{1}{ml^2} (b \dot{\theta} + mgl \sin \theta) 
\end{bmatrix} + 
\begin{bmatrix}
0 \\
\frac{1}{ml^2} 
\end{bmatrix} u, \quad y = \theta,
(\#eq:kbobserver-pendulum)
\end{equation}
where $\theta$ the angular position of the pendulum from the vertical line, $m > 0$ the mass of the pendulum, $l > 0$ the length, $g$ the gravitational constant, $b > 0$ the dampling coefficient, and $u$ the control input (torque). 

We assume we can only observe the angular position of the pendulum in \@ref(eq:kbobserver-pendulum), e.g., using a camera, but not the angular velocity. Our goal is to construct an observer that can provide a full state estimation. 

We first note that the pendulum dynamics \@ref(eq:kbobserver-pendulum) can actually be written in the (linear) Luenberger template \@ref(eq:Luenberger-linear-template) as^[I have to say I was a bit surprised when I arrived at this formulation.] 
\begin{equation}
\begin{split}
\dot{x} & = \underbrace{\begin{bmatrix}
0 & 1 \\
0 & - \frac{b}{ml^2}
\end{bmatrix}}_{=:A} x + 
\underbrace{\begin{bmatrix}
0 \\
\frac{u - mgl \sin \theta }{ml^2}
\end{bmatrix}}_{=:B(u,y)} \\
y & = \underbrace{\begin{bmatrix}
1 & 0
\end{bmatrix}}_{=:C} x 
\end{split}.
(\#eq:pendulum-state-affine)
\end{equation}

In order for us to use the Luenberger observer, we need to check if the pair $(A,C)$ is detectable. We can easily find the eigenvalues and eigenvectors of $A$:
$$
A \begin{bmatrix}
1 \\ 0
\end{bmatrix} = 0,\quad 
A \begin{bmatrix}
- \frac{ml^2}{b} \\ 1 
\end{bmatrix} = \begin{bmatrix}
1 \\ - \frac{b}{ml^2}
\end{bmatrix}
= - \frac{b}{ml^2} \begin{bmatrix}
- \frac{ml^2}{b} \\ 1 \end{bmatrix}.
$$
The first eigenvalue has real part equal to $0$. However, 
$$
C \begin{bmatrix}
1 \\ 0
\end{bmatrix} = 1 \neq 0.
$$
According to Theorem \@ref(thm:ltidetectable), we conclude $(A,C)$ is detectable. In fact, the pair $(A,C)$ is more than just detectable, it is indeed observable (according to Theorem \@ref(thm:ltiobservable)). Therefore, the poles of $A - KC$ can be arbitrarily placed. 

**Finding $K$**. Now we need to find $K$. An easy choice of $K$ is 
$$
K = \begin{bmatrix} k \\ 0 \end{bmatrix}, \quad A - KC = 
\begin{bmatrix}
- k & 1 \\ 0 & - \frac{b}{ml^2}
\end{bmatrix}.
$$
With $k > 0$, we know $A- KC$ is guaranteed to be Hurwitz (the two eigenvalues of $A-KC$ are $-k$ and $-b/ml^2$), and we have obtained an observer!

We can also estimate the convergence rate of this observer. Let us use $m=1,g=9.8,l=1,b=0.1$ as parameters of the pendulm dynamics. According to Theorem \@ref(thm:LuenbergerLinear), we solve the Lyapunov equation 
$$
(A - KC)^T P + P(A - KC) = -I
$$
and $\gamma = \frac{0.5}{\lambda_{\max}(P)}$ will be our best estimate of the convergence rate (of $\Vert e \Vert = \Vert \hat{x} - x \Vert$ towards zero). 

Table \@ref(tab:pendulumLuenbergerRate) below shows the convergence rates computed for different values of $k$. We can see that as $k$ is increased, the convergence rate estimation is also increased. However, it appears that $0.1$ is the best convergence rate we can achieve, regardless of how large $k$ is.

Table: (\#tab:pendulumLuenbergerRate) Convergence rate estimation of the Luenberger observer for a simple pendulm.

| $k$ | $0.1$ | $1$ | $10$ | $100$ | $1000$ | $10000$ |
|:-----------:|:----------:|:-----------:|:----------:|:----------:|:----------:|:----------:|
| $\gamma$ | $0.0019$ | $0.0523$ | $0.0990$ | $0.1000$ | $0.1000$ | $0.1000$ | 

**Optimal $K$**. Is it true that $0.1$ is the best convergence rate, or in other words, what is the best $K$ that maximizes the convergence rate $\gamma$? 

A natural way (and my favorite way) to answer this question is to formulate an optimization problem. 
\begin{equation}
\begin{split}
\min_{P,K} & \quad \lambda_{\max}(P) \\
\text{subject to} & \quad (A - KC)^T P + P (A - KC) = -I \\
& \quad P \succeq 0
\end{split}
(\#eq:pendulumLuenbergerMaxgammaNonCVX)
\end{equation}
The above formulation seeks the best possible $K$ that minimizes $\lambda_{\max}(P)$ which, according to $\gamma = 0.5 / \lambda_{\max}(P)$, also maximizes $\gamma$. 

However, problem \@ref(eq:pendulumLuenbergerMaxgammaNonCVX) is not a convex formulation due to the bilinear term $PK$. Nevertheless, via a simple change of variable $H = PK$, we arrive at the following convex formulation
\begin{equation}
\begin{split}
\min_{P,H} & \quad \lambda_{\max}(P) \\
\text{subject to} & \quad A^T P - C^T H^T + PA - H C = - I \\
& \quad P \succeq 0
\end{split}
(\#eq:pendulumLuenbergerMaxgammaCVX)
\end{equation}
Problem \@ref(eq:pendulumLuenbergerMaxgammaCVX) is a semidefinite programming problem (SDP), that can be modeled and solved by off-the-shelf tools. We can recover $K = P^{-1} H$ from \@ref(eq:pendulumLuenbergerMaxgammaCVX) after it is solved. 

Interestingly, solving problem \@ref(eq:pendulumLuenbergerMaxgammaCVX) verifies that the minimum $\lambda_{\max}(P)$ is $5$ and the maximum converge rate is $0.1$. An optimal solution of \@ref(eq:pendulumLuenbergerMaxgammaCVX) is
$$
P^\star = \begin{bmatrix}
2.4923 & 0 \\ 0 & 5 \end{bmatrix}, \quad 
K^\star = \begin{bmatrix}
0.2006 \\ 0.4985 \end{bmatrix}.
$$
You should check out the Matlab code of this example [here](https://github.com/ComputationalRobotics/OptimalControlEstimation-Examples/blob/main/pendulum_luenberger.m).
:::
:::


### State-affine Template 

Consider an instance of the normal form \@ref(eq:meta-observer-zeta) where the dynamics is linear in $\xi$, but the coefficients are time-varying and dependent on the input and output
\begin{equation}
\dot{\xi} = A(u,y) \xi + B(u,y), \quad y = C(u) \xi.
(\#eq:state-affine-template)
\end{equation}
The difference between the state-affine template \@ref(eq:state-affine-template) and the Luenberger template \@ref(eq:Luenberger-linear-template) is that the linear matrices $A,C$ are allowed to depend nonlinearly on the input $(u,y)$.

Kalman and Bucy originally proposed an observer for linear time-varying systems [@kalman61-new]. The result is later extened by [@besanccon96ejc-observer] and [@hammouri90cdc-observer] to deal with coefficient matrices dependent on the control. The following theorem is a direct extension of the result from [@besanccon96ejc-observer] and [@hammouri90cdc-observer] by considering $(u,y)$ as an augmented control input.

Before presenting the theorem, we need to introduce the following terminology.

::: {.definition #lineartimevarying name="Linear Time-Varying System"}
For a linear time-varying system of the form 
\begin{equation}
\dot{\chi} = A(\nu) \chi, \quad y = C(\nu) \chi,
(\#eq:linear-time-varying)
\end{equation}
with input $\nu$ and output $y$, we define

- the _transition matrix_ $\Psi_\nu$ as the unique solution to 
$$
\Psi_\nu (t,t) = I, \quad \frac{\partial \Psi_\nu}{\partial \tau}(\tau,t) = A(\nu(\tau)) \Psi_\nu (\tau, t).
$$
Note that the transition matrix is used to express the solution to \@ref(eq:linear-time-varying) because it satisfies 
$$
\chi(\chi_0,t_0;t;\nu) = \Psi_\nu (t,t_0) \chi_0.
$$

- the _observability grammian_ as 
$$
\Gamma_\nu (t_0,t_1) = \int_{t_0}^{t_1} \Psi_\nu (\tau,t_0)^T C(\nu(\tau))^T C(\nu(\tau)) \Psi_\nu (\tau,t_0) d\tau.
$$

- the _backward observability grammian_ as
$$
\Gamma_\nu^b (t_0,t_1) = \int_{t_0}^{t_1} \Psi_\nu (\tau,t_1)^T C(\nu(\tau))^T C(\nu(\tau)) \Psi_\nu (\tau,t_1) d\tau.
$$
:::

We now introduce the Kalman-Bucy Observer for the state-affine template \@ref(eq:state-affine-template).

::: {.theorembox}
::: {.theorem #kalmanbucystateaffine name="Kalman-Bucy Observer"}
Let $y_{\xi_0,u}(t) = C(u(t)) \Xi (\xi_0;t;u)$ be the output of system \@ref(eq:state-affine-template) at time $t$ with initialization $\xi_0$ and control $u$. Suppose the control $u$ satisfies 

- For any $\xi_0$, $t \mapsto A(u(t),y_{\xi_0,u}(t))$ is bounded by $A_{\max}$

- For any $\xi_0$, the augmented input $\nu = (u,y_{\xi_0,u})$ is _regularly persistent_ for the dynamics
\begin{equation}
\dot{\chi} = A(\nu) \chi , \quad y = C(\nu) \chi 
(\#eq:kbobserver-auxilarydynamics)
\end{equation}
uniformly with respect to $\xi_0$. That is, there exist strictly positive numbers $t_0,\bar{t}$, and $\alpha$ such that for any $\xi_0$ and any time $t \geq t_0 \geq \bar{t}$,
$$
\Gamma_v^b (t-\bar{t}, t) \succeq \alpha I,
$$
where $\Gamma_v^b$ is the _backward observability grammian_ associated with system \@ref(eq:kbobserver-auxilarydynamics). 

Then, given any positive definite matrix $P_0$, there exist $\alpha_1,\alpha_2 > 0$ such that for any $\lambda \geq 2 A_{\max}$ and any $\xi_0 \in \mathbb{R}^p$, the matrix differential equation 
\begin{equation}
\dot{P} = -\lambda P - A(u,y)^T P - P A(u,y) + C(u)^T C(u)
(\#eq:kbobserver-matrixdifferential)
\end{equation}
initialized at $P(0) = P_0$ admits a unique solution satisfying $P(t)=P(t)^T$ and 
$$
\alpha_2 I \succeq P(t) \succeq \alpha_1 I.
$$
Moreover, the system 
\begin{equation}
\dot{\hat{\xi}} = A(u,y) \hat{\xi} + B(u,y) + K (y - C(u)\hat{\xi})
(\#eq:kbobserver-observer)
\end{equation}
with a time-varying gain matrix
\begin{equation}
K = P^{-1} C(u)^T 
(\#eq:kbobserver-gain)
\end{equation}
is an observer for the state-affine system \@ref(eq:state-affine-template).
:::
:::

Let us work out an example of the Kalman-Bucy Observer for nonlinear systems.

::: {.examplebox}
::: {.example #pendulumkbobserver name="Kalman-Bucy Observer for A Simple Pendulum"}
Let us reconsider the pendulum dynamics \@ref(eq:kbobserver-pendulum) but this time try to design a Kalman-Bucy observer.

We first write the pendulum dynamics in a new coordinate system so that it is in the state-affine normal form \@ref(eq:state-affine-template). We choose $\xi = [\mathfrak{s},\mathfrak{c},\dot{\theta}]^T$ with $\mathfrak{s} = \sin \theta$ and $\mathfrak{c} = \cos \theta$. Clearly, we will be able to observe $y = [\mathfrak{s},\mathfrak{c}]^T$ in this new coordinate. The state-affine normal form of the pendulum dynamics reads
\begin{equation}
\begin{split}
\dot{\xi} = \begin{bmatrix}
\mathfrak{c} \dot{\theta} \\
- \mathfrak{s} \dot{\theta} \\
- \frac{1}{ml^2} (b \dot{\theta} + mgl \mathfrak{s} ) +  \frac{1}{ml^2} u
\end{bmatrix} & = 
\underbrace{\begin{bmatrix}
0 & 0 & \mathfrak{c} \\
0 & 0 & -\mathfrak{s} \\
0 & 0 & -\frac{b}{ml^2}
\end{bmatrix}}_{=:A(u,y)} \xi + 
\underbrace{\begin{bmatrix}
0 \\ 0 \\ \frac{u - mgl \mathfrak{s}}{ml^2}
\end{bmatrix}}_{=:B(u,y)} \\
y & = \underbrace{\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0
\end{bmatrix}}_{=:C(u)} \xi
\end{split}.
(\#eq:pendulum-state-affine)
\end{equation} 
Note that $C(u)$ is in fact time-invariant, and $B(u,y)$ only depends on $u$; but we adopt the same notation as the general state-affine template \@ref(eq:state-affine-template). 

In order to use the Kalman-Bucy observer in Theorem \@ref(thm:kalmanbucystateaffine), we need to verify the boundedness of $A(u,y)$, and the regular persistence of \@ref(eq:kbobserver-auxilarydynamics).

**Boundedness of $A(u,y)$**. We can easily show the boundedness of $A(u,y)$ by writing 
$$
\Vert A(u,y) \xi \Vert = \Vert \xi_3 (\mathfrak{c} - \mathfrak{s} - b/ml^2) \Vert  \leq |\xi_3| \sqrt{3} \sqrt{\mathfrak{c}^2 + \mathfrak{s}^2 + b^2 / m^2 l^4} \leq \Vert \xi \Vert \sqrt{3 + 3b^2 / m^2 l^4}. 
$$
Therefore, we can take $A_{\max} = \sqrt{3 + 3b^2 / m^2 l^4}$.
<span style="color:red">Does the $A_{\max}$ in Theorem \@ref(thm:kalmanbucystateaffine) refer to the bound in operator norm?</span>

**Regular persistence**. We write the backward observability grammian of system \@ref(eq:kbobserver-auxilarydynamics)
$$
\Gamma_\nu^b(t - \bar{t},t) = \int_{t - \bar{t}}^t \Psi_\nu(\tau,t)^T C^T C \Psi_\nu (\tau, t) d \tau = \int_{t - \bar{t}}^t \Psi_\nu(\tau,t)^T \underbrace{\begin{bmatrix} 
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 0
\end{bmatrix}}_{=:\tilde{C}}
\Psi_\nu (\tau, t) d \tau.
$$
$\Gamma_\nu^b(t - \bar{t},t) \succeq \alpha I$ if and only if
$$
w^T \Gamma_\nu^b(t - \bar{t},t) w \geq \alpha, \quad \forall w \in \mathbb{R}^3, \Vert w \Vert = 1.
$$
With this, we develop $w^T \Gamma_\nu^b(t - \bar{t},t) w$
\begin{equation}
\begin{split}
w^T \Gamma_\nu^b(t - \bar{t},t) w &= \int_{t - \bar{t}}^t s^T \tilde{C} s d\tau, \\
& = \int_{t - \bar{t}}^t \left( s_1^2 + s_2^2 \right) d\tau, \quad s = \Psi_\nu (\tau, t) w
\end{split}
(\#eq:pendulm-regular-persistence-1)
\end{equation}
and observe that $s = \Psi_\nu (\tau,t) w$ is equivalent to
$$
w = (\Psi_\nu (\tau,t))^{-1} s = \Psi_\nu (t,\tau) s,
$$
that is, $w$ is the solution of $\dot{\xi} = A(\nu) \xi$ at time $t$ with initial condition $s$ at time $\tau \leq t$. Equivalently, this is saying $s$ is the initial condition of $\dot{\xi} = A(\nu) \xi$ at time $\tau \leq t$ such that its solution at time $t$ is $w$. Note that from \@ref(eq:pendulm-regular-persistence-1) it is clearly that $\int_{t - \bar{t}}^t \left( s_1^2 + s_2^2 \right) d\tau \geq 0$, and $\int_{t - \bar{t}}^t \left( s_1^2 + s_2^2 \right) d\tau = 0$ if and only if $s_1^2 + s_2^2 = 0$, or equivalently $s_1 = s_2 = 0$ for any $\tau \in [t - \bar{t}, t]$.

We then take a closer look at the system $\dot{\xi} = A(\nu) \xi$:
\begin{align}
\dot{\xi}_1 &= \mathfrak{c} \xi_3 \\
\dot{\xi}_2 &= -\mathfrak{s} \xi_3 \\
\dot{\xi}_3 &= - \frac{b}{ml^2} \xi_3.
\end{align}
If the solution of $\xi_3$ at time $t$ is $w_3$, then 
$$
\xi_3(\tau) = w_3 e^{\frac{b}{ml^2}(t - \tau)}, \quad \tau \leq t.
$$
We can now claim it is impossible that $s_1 = s_2 = 0$ at any time $\tau \in [t - \bar{t}, t]$. 

We can show this by contradiction. First of all, $s_1 = s_2 = 0$ at $\tau = t$ implies $w_1 = w_2 = 0$ and hence $w_3 = \pm 1$. This implies $\xi_3 \neq 0$ for any $\tau \in [t - \bar{t}, t]$. Then, $s_1 = 0, \forall \tau \in [t - \bar{t}, t]$ implies $\dot{\xi}_1 = 0$ which, due to $\xi_3 \neq 0$, implies $\mathfrak{c} = 0$ for all $\tau$. Similarly, $s_2 = 0, \forall \tau \in [t - \bar{t}, t]$ implies $\dot{\xi}_2 = 0$ and $\mathfrak{s} = 0$. This creates a contradiction because $\mathfrak{c}^2 + \mathfrak{s}^2 = 1$ and $\mathfrak{c}, \mathfrak{s}$ cannot be simultaneously zero.

Therefore, there must exist $\alpha > 0$ such that $\Gamma_\nu^b (t - \bar{t},t) \succeq \alpha I$.
<!-- On the other hand,
$$
\frac{d}{d\tau}\left( \xi_1^2 + \xi_2^2 \right) = 2 \xi_1 \dot{\xi}_1 + 2 \xi_2 \dot{\xi}_2 = 2 \xi_3 \left(\mathfrak{c} \xi_1 - 2 \mathfrak{s}\xi_2 \right).
$$

This implies
$$
\xi_3^2 \leq w_3^2 e^{\frac{2b}{ml^2} \bar{t}}, \quad \forall t - \bar{t} \leq z \leq t. 
$$

On the other hand,
\begin{align}
(\dot{\xi}_1)^2 + (\dot{\xi}_2)^2 = (\mathfrak{c}^2 + \mathfrak{s}^2) \xi_3^2 \leq w_3^2 e^{\frac{2b}{ml^2} \bar{t}}, \quad \forall t - \bar{t} \leq z \leq t.
\end{align} -->
:::
:::

### Triangular Template


## Observer Feedback

Now that we have good ways to design a state observer, we will see how we can use the observer for feedback control. 

::: {.examplebox}
::: {.example #pendulumLuenbergerFeedback name="Pendulum Stabilization with A Luenberger Observer"}
In Example \@ref(exm:pendulumLuenberger), we have written the dynamics of a pendulum, and the dynamics of a Luenberger observer as 
\begin{align}
\dot{x} &= A x + B(u,y) \\
\dot{\hat{x}} &= A \hat{x} + B(u,y) + KC (x - \hat{x})
\end{align}
We wish to understand (so we can optimize) the behavior of this system under certain control input $u$. To do so, let us denote $e = \hat{x} - x$, and write the above dynamics as 
\begin{align}
\dot{x} &= A x + B(u,Cx) \\
\dot{e} & = (A - KC) e
\end{align}
Denoting $z = [x,e]^T$, we have the augmented dynamics 
$$
\dot{z} = \underbrace{\begin{bmatrix} A & 0 \\ 0 & A - KC \end{bmatrix}}_{=:F} z + \underbrace{\begin{bmatrix} B(u,Dz) \\ 0 \end{bmatrix}}_{=:G(z,u)}
$$
We want to stabilize the system at $z_0 = [\pi,0,0,0]^T$ (the upright position) subject to control bounds $u \in \mathbb{U} = [-u_{\max},u_{\max}]$.

We need to find a control Lyapunov function (CLF), $V(z)$, that satisfies the following constraints:
$$
    V(z_0) = 0
$$
$$
    V(z) > 0 \quad \forall x \in \mathcal{X} \,\, \backslash \,\,\{x_g\}
$$
$$
    \inf_{u \in \mathcal{U}} [L_F V(x) + L_G V(x)u] \leq 0 \quad \forall x \in \mathcal{X}
$$

where $L_F V$ and $L_G V$ are the Lie derivatives of $V$ along $F$ and $G$, respectively. The CLF will define the set of admissable control inputs as follows:
$$
    K = \{ u: L_f V(x) + L_g V(x)u \leq 0 \}
$$
To find the smallest-magnitude control input such that $u \in K$, we may use a quadratic program:

$$
    \min_{u \in \mathcal{U}} ||u||^2
$$
$$
\mathrm{s.t.} \quad L_f V(x) + L_g V(x)u \leq -c V(x)
$$

where $c$ is some positive constant.

<!-- \inf_{u \in \mathcalU}
-->

<!-- Our controller has access to the observation $y$ (recall this is $\theta$) and the estimated state $\hat{x}$. Let us try a controller of the following form
$$
u = mgl \sin \theta - G \hat{x} = mgl \sin \theta - G (x + e).
$$
This leads to the dynamics 
\begin{align}
\dot{x} & = A x - \frac{1}{ml^2} G (x + e) = \left( A - \frac{1}{ml^2}G \right)x - \frac{1}{ml^2} G e \\
\dot{e} & = (A - KC)e
\end{align} -->
:::
:::